{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Rotating Logos - Reference Set Different Distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7194a5f23b94143f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import relevant libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy as sci\n",
    "import tqdm\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import helper_functions.plotting_funcs as plot_funcs\n",
    "from helper_functions.logo_funcs import imresize_pad, lin2circ_angles, get_validation_indices\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sim_params = {\n",
    "        'delete_kernels': False,\n",
    "        'generate_data': False,\n",
    "        'evd_solver': 'arpack',  # 'arpack' / 'randomized' / 'svd'\n",
    "        'ad_methods': ['lead', 'forward_only', 'ncca', 'kcca_impute', 'nystrom', 'adm_plus', 'backward_only'],\n",
    "        'embed_dim': 2,\n",
    "        't': 0,\n",
    "        'scales': [2, 8, 10, 20],\n",
    "        'angle_bias_factor_max': 0.8,\n",
    "        'angles_for_bias': 'mnm',\n",
    "        'im_resize_factor': 2,\n",
    "        'Nr': 50,  # number of samples in the reference set,\n",
    "        'N' : 1000, # number of total samples\n",
    "        'valid_size': 0.2,\n",
    "    }\n",
    "\n",
    "fig_str = f\"figures/logos_rs_factor_{sim_params['im_resize_factor']}_{sim_params['evd_solver']}_N_{sim_params['N']}_Nr_{sim_params['Nr']}_diff_dist\".replace('.', 'p')\n",
    "# figures_path = f\"{fig_str}_{sim_params['N']}\"\n",
    "figures_path = f\"{fig_str}\"\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "Nr = sim_params['Nr'] # number of samples in the reference set\n",
    "N_d = sim_params['N']\n",
    "\n",
    "\n",
    "# save params to json\n",
    "with open(f\"{figures_path}/sim_params.json\", 'w') as fp:\n",
    "    json.dump(sim_params, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "font_name = \"Times New Roman\"  # Change to any other installed serif font if needed\n",
    "\n",
    "# Set font properties using the font name\n",
    "# 2 plots at a row \n",
    "font_properties_title = font_manager.FontProperties(family=font_name, size=28)\n",
    "font_properties_ticks = font_manager.FontProperties(family=font_name, size=22)\n",
    "figsize = (8, 7) \n",
    "# 3 plots in a row \n",
    "# font_properties_title = font_manager.FontProperties(family=font_name, size=38)\n",
    "# font_properties_ticks = font_manager.FontProperties(family=font_name, size=32)\n",
    "# figsize = (8, 7)  # 2 plot size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2789e15b4f753960",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "902e815ec149f709"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Load Logo images \n",
    "# KFC logo\n",
    "img = cv2.imread('KFC_logo')\n",
    "img_kfc = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# M&M logo\n",
    "img = cv2.imread('mnm_logo.jpg')\n",
    "img_mnm = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_mnm_g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Starbucks logo\n",
    "img = cv2.imread('starbucks_logo.jpg')\n",
    "img_str = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_str_g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# resize images so they can be concatenated \n",
    "height = 400 # height needs to be uniform for concatanation\n",
    "\n",
    "# KFC resize\n",
    "kfc_scale = img_kfc.shape[0]/height\n",
    "kfc_width = int(img_kfc.shape[1]/kfc_scale)\n",
    "img_kfc_rs = cv2.resize(img_kfc,(kfc_width,height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# M&M resize\n",
    "mnm_scale = img_mnm.shape[0]/height\n",
    "mnm_width = int(img_mnm.shape[1]/mnm_scale)\n",
    "img_mnm_rs = cv2.resize(img_mnm,(mnm_width,height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Starbucks resize\n",
    "str_scale = img_str.shape[0]/height\n",
    "str_width = int(img_str.shape[1]/str_scale)\n",
    "img_str_rs = cv2.resize(img_str,(str_width,height), interpolation = cv2.INTER_AREA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc014bcb1c3d449d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Example of Rotation for Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43333113f8b91d69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## concatenate Image rotations to simulate two sensors \n",
    "angle_KFC = 30\n",
    "angle_MNM = 74\n",
    "angle_STR = 110\n",
    "\n",
    "# resize M&M\n",
    "mnm_resized = imresize_pad(img_mnm_rs,sim_params['im_resize_factor'])\n",
    "\n",
    "# rotate images \n",
    "kfc_rot = ndimage.rotate(img_kfc_rs, angle_KFC, reshape=False, mode='nearest')\n",
    "mnm_rot = ndimage.rotate(mnm_resized, angle_MNM, reshape=False, mode='nearest')\n",
    "str_rot = ndimage.rotate(img_str_rs, angle_STR, reshape=False, mode='nearest')\n",
    "\n",
    "# Concatenate \n",
    "sensor_1 = np.concatenate((kfc_rot, mnm_rot),axis=1)\n",
    "sensor_2 = np.concatenate((mnm_rot, str_rot),axis=1)\n",
    "total_scene = np.concatenate((sensor_1, str_rot),axis=1)\n",
    "\n",
    "# plot parameters\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 18\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.5\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "\n",
    "# plot images\n",
    "fig, ax = plot_funcs.subplots_imshow(1, 1, figsize=(8, 4))\n",
    "ax.imshow(sensor_1, cmap=plt.cm.gray)\n",
    "ax.set_title(\"Sensor 1\", font_properties=font_properties_title)\n",
    "plt.savefig(f\"{figures_path}/sensor1_scene.pdf\", dpi = 300, format = 'pdf', bbox_inches='tight')\n",
    "fig, ax = plot_funcs.subplots_imshow(1, 1, figsize=(8, 4))\n",
    "ax.imshow(sensor_2, cmap=plt.cm.gray)\n",
    "ax.set_title(\"Sensor 2\", font_properties=font_properties_title)\n",
    "plt.savefig(f\"{figures_path}/sensor2_scene.pdf\", dpi = 300, format = 'pdf', bbox_inches='tight')\n",
    "fig, ax = plot_funcs.subplots_imshow(1, 1, figsize=(16, 8))\n",
    "ax.imshow(total_scene, cmap=plt.cm.gray)\n",
    "ax.set_title(\"Whole Scene\", font_properties=font_properties_title)\n",
    "plt.savefig(f\"{figures_path}/whole_scene.pdf\", dpi = 300, format = 'pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1bfbccbe8d70167",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Dataset of Synchronized Pairs Rotating images\n",
    "We create a dataset of 2 sensors measuring 2 pairs of images with a common image and a different image.\\\n",
    "We aim to create an embedding of the common variable - the rotation angle of the common logo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90c9121b365d0c91"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# define rotation angular velocities\n",
    "w_kfc = 2.93 * 4 # [degrees/timestamp]\n",
    "w_str = 1.27 * 4# [degrees/timestamp]\n",
    "w_mnm = 2.11 * 4# [degrees/timestamp]\n",
    "\n",
    "# calculate angles \n",
    "angles_kfc_d = lin2circ_angles(w_kfc*np.linspace(0, N_d-1, N_d))\n",
    "angles_mnm_d = lin2circ_angles(w_mnm*np.linspace(0, N_d-1, N_d)) # generate angle vectors for dataset \n",
    "angles_str_d = lin2circ_angles(w_str*np.linspace(0, N_d-1, N_d)) # generate angle vectors for dataset "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe22d6ae308d7d6c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Create Dataset - Deterministic Rotation\n",
    "if sim_params['generate_data'] or not os.path.isfile(f\"{figures_path}/s1_low_csr.npy\"):\n",
    "    d1 = sensor_1.size # number of pixels/dimension of data points\n",
    "    d2 = sensor_2.size # number of pixels/dimension of data points\n",
    "    s1_points_d = np.zeros((N_d, d1), dtype='uint8') # initalize data points \n",
    "    s2_points_d = np.zeros((N_d, d2), dtype='uint8') # initalize data points \n",
    "    \n",
    "    for i in tqdm.tqdm(range(N_d)):\n",
    "        # rotate images\n",
    "        kfc_rot = ndimage.rotate(img_kfc_rs, angles_kfc_d[i], reshape=False, mode='nearest')\n",
    "        mnm_rot = ndimage.rotate(mnm_resized, angles_mnm_d[i], reshape=False, mode='nearest')\n",
    "        str_rot = ndimage.rotate(img_str_rs, angles_str_d[i], reshape=False, mode='nearest')\n",
    "        # concatenate images\n",
    "        sensor_1 = np.concatenate((kfc_rot, mnm_rot), axis=1)\n",
    "        sensor_2 = np.concatenate((mnm_rot, str_rot), axis=1)\n",
    "        # flatten images to create a vector\n",
    "        s1_points_d[i,:] = sensor_1.reshape((1, d1))\n",
    "        s2_points_d[i,:] = sensor_2.reshape((1, d2))\n",
    "        \n",
    "    %time np.save(f\"{figures_path}/s1_low_csr\", s1_points_d)\n",
    "    %time np.save(f\"{figures_path}/s2_low_csr\", s2_points_d)\n",
    "    \n",
    "    print('Successfully Generated Dataset')\n",
    "else:\n",
    "    print('Data Already Generated')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4cd9ddab757d595",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56bcc9a22d8f1d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "s1_points_d = np.load(f\"{figures_path}/s1_low_csr.npy\")\n",
    "s2_points_d = np.load(f\"{figures_path}/s2_low_csr.npy\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c74dfd6f5457678a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the Data into Reference Set and Total Set\n",
    "We take samples of the rotation process by subsampling of the rotation times."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a2c76c2bd090415"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sample_reference_set(s1, s2, angles, Nr, bias_factor=1):\n",
    "    # define probability weights \n",
    "    weights = (angles / np.max(angles)) ** bias_factor\n",
    "    \n",
    "    # normalize weights to get probabilities\n",
    "    normalized_weights = weights / np.sum(weights)\n",
    "    \n",
    "    # randomly sample Nr angles with probability weight\n",
    "    ref_idx = np.random.choice(len(angles), size=Nr, replace=False, p=normalized_weights)\n",
    "    \n",
    "    # select views\n",
    "    total_idx = np.round(np.linspace(0, N_d - 1, N_d)).astype(int)\n",
    "    single_idx = [i for i in total_idx if i not in ref_idx] # the rest of the indices \n",
    "    reorder_idx = np.concatenate((ref_idx, single_idx))\n",
    "    reorder_idx = np.argsort(reorder_idx)\n",
    "    \n",
    "    # split reference set\n",
    "    s1_ref = s1[ref_idx, :]\n",
    "    s2_ref = s2[ref_idx, :]\n",
    "    \n",
    "    # create single sensor set - only with samples from sensor 1\n",
    "    s1_single = s1[single_idx, :]\n",
    "    s1_aligned = np.concatenate((s1_ref, s1_single), axis=0)\n",
    "    s2_single = s2[single_idx, :] # save sensor 2 images for reference to completed images\n",
    "    s2_aligned = np.concatenate((s2_ref, s2_single), axis=0)\n",
    "    \n",
    "    return s1_ref, s2_ref, s1_aligned, s2_aligned, reorder_idx, ref_idx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1417dcb9aa04075b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## select in which angle to create bias\n",
    "if sim_params['angles_for_bias'] == 'mnn':\n",
    "    angles = angles_mnm_d\n",
    "elif sim_params['angles_for_bias'] == 'str':\n",
    "    angles = angles_str_d\n",
    "else:\n",
    "    angles = angles_kfc_d\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1170a41e00de8a3c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run all methods"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81ddee1d2ea4218"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from helper_functions.AD_funcs import Create_Transition_Mat, Create_Asym_Tran_Kernel, embed_wrapper\n",
    "embed_dict = dict()\n",
    "bias_factors = np.linspace(0, sim_params['angle_bias_factor_max'], 6)\n",
    "for bias_factor in bias_factors:\n",
    "    s1_ref, s2_ref, s1_aligned, s2_aligned, reorder_idx, ref_idx = sample_reference_set(s1_points_d, s2_points_d, angles, Nr, bias_factor)\n",
    "    for scale in tqdm.tqdm(sim_params['scales']):\n",
    "        A1, _, _ = Create_Asym_Tran_Kernel(s1_aligned, s1_ref, mode='median', scale=scale)\n",
    "        A2, _, _ = Create_Asym_Tran_Kernel(s2_aligned, s2_ref, mode='median', scale=scale)\n",
    "        K1, _ = Create_Transition_Mat(s1_aligned, scale=scale)\n",
    "        K2, _ = Create_Transition_Mat(s2_aligned, scale=scale)\n",
    "        K1_ref, _ = Create_Transition_Mat(s1_ref, scale=scale)\n",
    "        K2_ref, _ = Create_Transition_Mat(s2_ref, scale=scale)\n",
    "    \n",
    "        for method in sim_params['ad_methods']:\n",
    "            dict_key = f'{method}_scale_{scale}_factor_{bias_factor}'\n",
    "            if method in {\"forward_only\", \"forward_only_slow\", \"alternating_roseland\", \"ffbb\", \"fbfb\", \"ncca\", \"kcca\", \"nystrom\", 'adm_plus', 'backward_only'}:\n",
    "                embed = embed_wrapper(s1_ref, s1_aligned, s2_ref, s2_aligned, method=method,\n",
    "                              embed_dim=sim_params['embed_dim'], t=sim_params['t'],\n",
    "                              K1=A1, K2=K2_ref, solver=sim_params['evd_solver'],\n",
    "                              delete_kernels=sim_params['delete_kernels'])\n",
    "                embed_dict[dict_key] = embed[reorder_idx, :]\n",
    "            elif method in {\"ad\", 'dm', 'kcca_full'}:\n",
    "                embed = embed_wrapper(s1_ref, s1_aligned, s2_ref, s2_aligned, method=method,\n",
    "                                  embed_dim=sim_params['embed_dim'], t=sim_params['t'],\n",
    "                                  K1=K1, K2=K2, solver=sim_params['evd_solver'],\n",
    "                                  delete_kernels=sim_params['delete_kernels'])\n",
    "                embed_dict[dict_key] = embed[reorder_idx, :]\n",
    "            elif method in {\"kcca_impute\"}:\n",
    "                embed = embed_wrapper(s1_ref, s1_aligned, s2_ref, s2_aligned, method=method,\n",
    "                                  embed_dim=sim_params['embed_dim'], t=sim_params['t'],\n",
    "                                  K1=K1, K2=K2_ref, solver=sim_params['evd_solver'],\n",
    "                                  delete_kernels=sim_params['delete_kernels'])\n",
    "                embed_dict[dict_key] = embed[reorder_idx, :]\n",
    "            elif method == \"lead\":\n",
    "                embed = embed_wrapper(s1_ref, s1_aligned, s2_ref, s2_aligned, method=method,\n",
    "                                  embed_dim=sim_params['embed_dim'], t=sim_params['t'],\n",
    "                                  K1=A1, K2=A2, solver=sim_params['evd_solver'],\n",
    "                                  delete_kernels=sim_params['delete_kernels'])\n",
    "                embed_dict[dict_key] = embed[reorder_idx, :]\n",
    "            \n",
    "    # save embeddings to file\n",
    "with open(f\"{figures_path}/embedding_dictionary.pkl\", 'wb') as fp:\n",
    "    pickle.dump(embed_dict, fp)\n",
    "    print('dictionary saved successfully to file')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53a31721159fbb9c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read dictionary pkl file\n",
    "with open(f\"{figures_path}/embedding_dictionary.pkl\", 'rb') as fp:\n",
    "    embed_dict = pickle.load(fp)\n",
    "    print('Dictionary Loaded Successfully')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b63489bbb0f62b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_method_embedding(embed, figures_path, angles, Nr, method, ref_idx, plot_flag=True, pointsize=20,\n",
    "                          pointsize_ref=30, fontproperties=None, tick_fontproperties=None, figsize=(8, 7)):\n",
    "    fig, ax = plot_funcs.subplots_plot(1, 1, figsize=figsize)\n",
    "    colors = lin2circ_angles(angles)\n",
    "    N_d = embed.shape[0]\n",
    "    total_idx = np.round(np.linspace(0, N_d - 1, N_d)).astype(int)\n",
    "    single_idx = [i for i in total_idx if i not in ref_idx]\n",
    "    # define font\n",
    "    if fontproperties is None:\n",
    "        my_fontproperties = font_manager.FontProperties(family='Times New Roman', size=18)\n",
    "    else:\n",
    "        my_fontproperties = fontproperties\n",
    "    if tick_fontproperties is None:\n",
    "        my_tick_fontproperties = font_manager.FontProperties(family='Times New Roman', size=18)\n",
    "    else:\n",
    "        my_tick_fontproperties = tick_fontproperties\n",
    "    ax.scatter(embed[ref_idx, 0], embed[ref_idx, 1], marker='x', c=colors[ref_idx],\n",
    "               label='Reference', s=pointsize_ref)\n",
    "    ax.scatter(embed[single_idx, 0], embed[single_idx, 1], marker='.', c=colors[single_idx],\n",
    "               label='Out of Reference', s=pointsize)\n",
    "\n",
    "    # plot a circle to show how well it fits into a circle\n",
    "    # Calculate radii from the origin (assuming points are centered at (0, 0))\n",
    "    radii = np.linalg.norm(embed, axis=1)\n",
    "    median_radius = np.median(radii)\n",
    "    quantile_15 = np.quantile(radii, 0.15)\n",
    "    quantile_85 = np.quantile(radii, 0.85)\n",
    "\n",
    "    # Plot the median radius circle\n",
    "    circle = plt.Circle((0, 0), median_radius, color='black', linestyle='--', fill=False, label='Median Radius')\n",
    "    ax.add_artist(circle)\n",
    "    # circle = plt.Circle((0, 0), quantile_25, color='gray', linestyle='--', alpha=0.5, fill=False,\n",
    "    #                     label='0.25 Quant Radius')\n",
    "    # ax.add_artist(circle)\n",
    "    # circle = plt.Circle((0, 0), quantile_75, color='gray', linestyle='--', alpha=0.5, fill=False,\n",
    "    #                     label='0.75 Quant Radius')\n",
    "    # ax.add_artist(circle)\n",
    "\n",
    "    # Plot the shaded region for the 0.25 and 0.75 quantile radii\n",
    "    theta = np.linspace(0, 2 * np.pi, 100)\n",
    "    x_quantile_15 = quantile_15 * np.cos(theta)\n",
    "    y_quantile_15 = quantile_15 * np.sin(theta)\n",
    "    x_quantile_85 = quantile_85 * np.cos(theta)\n",
    "    y_quantile_85 = quantile_85 * np.sin(theta)\n",
    "    ax.fill(np.concatenate([x_quantile_85, x_quantile_15[::-1]]),\n",
    "                np.concatenate([y_quantile_85, y_quantile_15[::-1]]),\n",
    "                color='gray', alpha=0.3, label='0.15-0.85 Quantile Radius')\n",
    "\n",
    "    # Set axis aspect ratio to be equal\n",
    "    # ax.set_aspect('equal')\n",
    "    max_extent = np.max(np.abs(embed)) * 1.1  # Add a small margin\n",
    "    ax.set_xlim(-max_extent, max_extent)\n",
    "    ax.set_ylim(-max_extent, max_extent)\n",
    "    \n",
    "    # ax.set_title(\"M&M Angle Colors - Spectral Completed Data, $N_R = {}$\".format(Nr))\n",
    "    ax.set_xlabel(\"First Diffusion Coordinate\", font_properties=my_fontproperties)\n",
    "    ax.set_ylabel(\"Second Diffusion Coordinate\", font_properties=my_fontproperties)\n",
    "    # ax.legend(loc='upper right')\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontproperties(my_tick_fontproperties)\n",
    "    if plot_flag:\n",
    "        plt.show()\n",
    "    \n",
    "    # Display the normalized ring width in the second figure\n",
    "    normalized_ring_width = (quantile_85 - quantile_15) / median_radius\n",
    "    ax.text(1, 1, f'Width = {normalized_ring_width:.2f} Median(R)',\n",
    "            transform=ax.transAxes, fontsize=22, fontproperties=my_fontproperties,\n",
    "            verticalalignment='top', horizontalalignment='right')\n",
    "    \n",
    "    plt.savefig(f\"{figures_path}/{method}_embedding.pdf\", dpi=300, format='pdf', bbox_inches='tight')\n",
    "\n",
    "    fig, ax = plot_funcs.subplots_plot(1, 1, figsize=figsize)\n",
    "    ax.scatter(embed[single_idx, 0], embed[single_idx, 1], marker='.', c='r',\n",
    "               label='Out of Reference', s=pointsize)\n",
    "    ax.scatter(embed[ref_idx, 0], embed[ref_idx, 1], marker='.', c='b', label='Reference', s=pointsize)\n",
    "    # ax.set_title(\"Spectral Completed - Reference Vs. Completed\")\n",
    "    ax.set_xlabel(\"First Diffusion Coordinate\", font_properties=my_fontproperties)\n",
    "    ax.set_ylabel(\"Second Diffusion Coordinate\", font_properties=my_fontproperties)\n",
    "    \n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontproperties(my_fontproperties)\n",
    "    if plot_flag:\n",
    "        plt.show()\n",
    "    plt.savefig(f\"{figures_path}/{method}_embedding_comp_vs_ref.pdf\", dpi=300, format='pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38f64062dbe01f54",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plot and save embeddings\n",
    "# from helper_functions.logo_funcs import plot_method_embedding\n",
    "for method in embed_dict.keys():\n",
    "    plot_method_embedding(embed_dict[method], figures_path, angles_mnm_d, Nr, method, ref_idx, plot_flag=False, pointsize=20, pointsize_ref=30, fontproperties=font_properties_ticks, figsize=figsize)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f20c2739ede97cfc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a683bcdb3666acfd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helper_functions.logo_funcs import embed_error\n",
    "# calculate Error per Method\n",
    "errors = []\n",
    "# randomly select validation set\n",
    "validation_idx = get_validation_indices(sim_params, seed=0)\n",
    "# calculate error for each method\n",
    "for key in embed_dict.keys():\n",
    "    embed = np.real(embed_dict[key])\n",
    "    error_mae, error_std = embed_error(embed, angles_mnm_d, plot_flag=False, metric='MAE')\n",
    "    error_mae_val, _ = embed_error(embed[validation_idx, :], angles_mnm_d[validation_idx], plot_flag=False, metric='MAE')\n",
    "    error_mse, _ = embed_error(embed, angles_mnm_d, plot_flag=False, metric='RMSE')\n",
    "    error_mae_center, error_std_center = embed_error(embed, angles_mnm_d, plot_flag=False, metric='MAE', center_data=True)\n",
    "    error_mse_center, _ = embed_error(embed, angles_mnm_d, plot_flag=False, metric='RMSE', center_data=True)\n",
    "    parts = key.split('_scale_')\n",
    "    method = parts[0]\n",
    "    parts = parts[1].split('_factor_')\n",
    "    scale = float(parts[0])\n",
    "    bias_factor = float(parts[1])\n",
    "    new_line = {'Method' : method,\n",
    "                'scale': scale,\n",
    "                'bias_factor': bias_factor,\n",
    "                'RMSE' : error_mse,\n",
    "                'MAE' : error_mae,\n",
    "                'MAE_valid': error_mae_val,\n",
    "                'STD' : error_std,\n",
    "                'RMSE w centered data' : error_mse_center,\n",
    "                'MAE w centered data' : error_mae_center,\n",
    "                'STD center' : error_std_center,\n",
    "                'ref mean radius' : np.mean(np.sqrt(embed[:Nr, 0] ** 2 + embed[:Nr, 1] ** 2)),\n",
    "                'out of ref mean radius' : np.mean(np.sqrt(embed[Nr:, 0] ** 2 + embed[Nr:, 1] ** 2))\n",
    "                }\n",
    "    errors.append(new_line)\n",
    "\n",
    "error_df = pd.DataFrame(errors)\n",
    "error_df.to_csv(f\"{figures_path}/results_{sim_params['evd_solver']}.csv\")\n",
    "error_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86aab9516f93b5ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_error_df = error_df.loc[error_df.groupby(['Method', 'bias_factor'])['MAE_valid'].idxmin()]\n",
    "best_error_df.to_csv(f\"{figures_path}/results_best.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "550168958e6aacb6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Post Processing "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d2a05c73e2c403c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load results\n",
    "summary_path = f\"{figures_path}/summary\"\n",
    "results_df = pd.read_csv(f'{figures_path}/results_best.csv')\n",
    "\n",
    "os.makedirs(summary_path, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c96c7553ee659f6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# format\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle': '--'})  # Adjust grid style\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{newtxmath} \\usepackage{newtxtext} \\usepackage{newtxtext}'\n",
    "plt.rcParams['font.serif'] = \"Times New Roman\"\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.5\n",
    "plt.rcParams['grid.linestyle'] = '--'\n",
    "\n",
    "font_name = \"Times New Roman\"  # Change to any other installed serif font if needed\n",
    "\n",
    "# Set font properties using the font name\n",
    "font_properties = font_manager.FontProperties(family=font_name, size=18)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41da6fafdfee7952",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reference_methods = ['lead']  # methods for performance reference \n",
    "competing_methods = ['nystrom', 'ncca']  # competing methods under the same setting\n",
    "our_methods = ['adm_plus', 'forward_only', 'backward_only']\n",
    "\n",
    "method_names = {\n",
    "    'lead': 'LAD',\n",
    "    'ad': 'ADM',\n",
    "    'dm': 'DM',\n",
    "    # 'nystrom': 'Nyström',\n",
    "    'nystrom': 'Dov et al.',\n",
    "    'ncca': 'NCCA',\n",
    "    'kcca': 'KCCA (ChatGPT)',\n",
    "    'kcca_impute': 'KCCA',\n",
    "    'forward_only': 'forward only',\n",
    "    'backward_only': 'backward only',\n",
    "    'adm_plus': 'ADM+'\n",
    "}\n",
    "\n",
    "# Specify the color palette for different methods\n",
    "palette_reference = {'ad': 'black', 'dm': 'grey', 'lead': 'black'}  # Reference methods: black and grey\n",
    "palette_our_methods = {'forward_only': 'blue', 'adm_plus': 'dodgerblue', 'backward_only': 'cyan'}  # Our methods in shades of blue\n",
    "palette_competing = {'nystrom': 'green', 'ncca': 'orange', 'kcca': 'violet', 'kcca_impute': 'purple'}  # Competing methods in other colors\n",
    "\n",
    "# linestyle\n",
    "linewidth = 3.5\n",
    "errorbar = 'sd'\n",
    "\n",
    "# fonts \n",
    "legend_fontsize = 26\n",
    "label_fontsize = 26\n",
    "tick_fontsize = 32\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7389c7c684c9fcfa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Filter the dataframe for the current train_percent value and selected methods \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for reference methods with dashed lines\n",
    "df_filtered = results_df[results_df['Method'].isin(reference_methods)]\n",
    "ax = sns.lineplot(data=df_filtered, x='bias_factor', y=r'MAE', hue='Method',\n",
    "                  marker='o', palette=palette_reference, linewidth=linewidth,\n",
    "                  hue_order=reference_methods, estimator='mean', linestyle='dashed', errorbar=errorbar)\n",
    "\n",
    "# Plot for competing methods\n",
    "df_filtered = results_df[results_df['Method'].isin(competing_methods)] \n",
    "ax = sns.lineplot(data=df_filtered, x='bias_factor', y='MAE', hue='Method',\n",
    "                  marker='o', palette=palette_competing, linewidth=linewidth,\n",
    "                  hue_order=competing_methods, estimator='mean', errorbar=errorbar)\n",
    "\n",
    "# Plot for our methods\n",
    "df_filtered = results_df[results_df['Method'].isin(our_methods)]\n",
    "ax = sns.lineplot(data=df_filtered, x='bias_factor', y='MAE', hue='Method',\n",
    "                  marker='o', palette=palette_our_methods, linewidth=linewidth,\n",
    "                  hue_order=our_methods, estimator='mean', errorbar=errorbar)\n",
    "\n",
    "# Modify the legend with custom names\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "labels = [method_names[label] for label in labels]\n",
    "plt.legend(handles, labels, title_fontsize=22, fontsize=22, loc='lower right', frameon=True, prop=font_properties)\n",
    "\n",
    "# Enhancing the plot\n",
    "# plt.title(f'Accuracy vs Dim for each Method (train_percent={train_percent})', fontsize=16, weight='bold', fontproperties=font_properties)\n",
    "# plt.xlabel('Train Size[%]', fontsize=label_fontsize, fontproperties=font_properties)\n",
    "\n",
    "plt.xlabel(r'$\\alpha$', fontsize=label_fontsize)\n",
    "plt.ylabel(r'MAE[deg]', fontsize=label_fontsize)\n",
    "plt.xticks(fontsize=tick_fontsize)  # Increase x-tick fontsize\n",
    "plt.yticks(fontsize=tick_fontsize)  # Increase y-tick fontsize\n",
    "ax.tick_params(axis='x', labelsize=24)\n",
    "ax.tick_params(axis='y', labelsize=24)\n",
    "# ax.set_ylim([0.1, 1.0])\n",
    "\n",
    "# ax.legend().set_visible(True)\n",
    "\n",
    "# Adding gridlines for better readability\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.6)\n",
    "\n",
    "# Remove the top and right spines for a cleaner look\n",
    "sns.despine()\n",
    "plt.savefig(f'{summary_path}/alpha_vs_mae.pdf', dpi=300, format='pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f1c0917ecdb59f2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Biased sampling test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d28e6ef92f4526d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define probability weights \n",
    "bias_factors = np.linspace(0, 5, 30)\n",
    "angles = np.linspace(0, 360, 1000)\n",
    "# angles = angles_mnm_d\n",
    "Nr = sim_params['Nr']\n",
    "avg_angles = np.zeros(bias_factors.shape)\n",
    "seeds = [0, 32, 192, 240, 211]\n",
    "for seed in seeds:\n",
    "    for i, bias_factor in enumerate(bias_factors):\n",
    "        weights = (angles / np.max(angles)) ** bias_factor\n",
    "        \n",
    "        # normalize weights to get probabilities\n",
    "        normalized_weights = weights / np.sum(weights)\n",
    "        \n",
    "        # randomly sample Nr angles with probability weight\n",
    "        np.random.seed(seed)\n",
    "        ref_idx = np.random.choice(len(angles), size=Nr, replace=False, p=normalized_weights)\n",
    "        \n",
    "        sampled_angles = angles[ref_idx]\n",
    "        avg_angles[i] += sampled_angles.mean()\n",
    "\n",
    "avg_angles /= len(seeds)\n",
    "# plot \n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(bias_factors, avg_angles)\n",
    "ax.set_xlabel(r'$\\alpha$', fontsize=20)\n",
    "ax.set_ylabel(r'$\\theta_{avg}$', fontsize=20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60c29d011871e487",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
