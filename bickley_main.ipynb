{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bickley Data Experiment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c938768cf15de832"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### Import relevant libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import font_manager\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from helper_functions.bickley_funcs import (align_clusters, dynamic_isoperimetric_score, flatten_timeseries, \n",
    "                                            calc_graph_dynamic_isoperim, calc_graph_dynamic_isoperim_4, calc_embed_isoperim)\n",
    "from helper_functions.bickley_funcs import (create_dataset, create_views, plot_clustering)\n",
    "\n",
    "sim_params = {\n",
    "        'delete_kernels': False,\n",
    "        'generate_data': True,\n",
    "        'animate' : True,  #  animation generation increases the run time\n",
    "        'evd_solver': 'arpack',  # 'arpack' / 'randomized' / 'svd'\n",
    "        'ad_methods': ['ad', 'alternating_roseland', 'ffbb', 'fbfb', 'lead', 'forward_only', 'ncca', 'kcca_impute', 'kcca', 'nystrom', 'adm_plus', 'backward_only'],\n",
    "        # 'ad_methods': ['adm_plus', 'backward_only'],\n",
    "        'embed_dim': 20,\n",
    "        'clusters': 9,\n",
    "        't': 1,\n",
    "        'scale': 1,\n",
    "        'sigma_mode' : 'scale',  # 'median' , 'scale'\n",
    "        'Nr': 3000,  # number of samples in the reference set,\n",
    "        'N' : 4000, # number of total samples\n",
    "        'lag' : 200,  # lag between trajectories for short_traj mode\n",
    "        'traj_len' : 1,  # for short_traj mode\n",
    "        'times': [199, 400, 250, 300], # times for view generation (multi_frame) first 2 times are for the embedding views and the last are for evaluation of the dynamic isoperimetry score\n",
    "        'views': 'multi_frame',  # 'frame' , 'traj' , 'short_traj', 'multi_frame'\n",
    "        'cmap': 'custom',\n",
    "        'reps': 10\n",
    "    }\n",
    "\n",
    "fig_str = f\"figures/bickley\"\n",
    "figures_path = f\"{fig_str}_{sim_params['N']}_lag_{sim_params['lag']}_{sim_params['views']}_tlen_{sim_params['traj_len']}_scale_{sim_params['scale']}_final_run\".replace('.', 'p')\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "Nr = sim_params['Nr'] # number of samples in the reference set\n",
    "N_d = sim_params['N']\n",
    "\n",
    "with open(f\"{figures_path}/sim_params.json\", 'w') as fp:\n",
    "    json.dump(sim_params, fp, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fedf42a0b356482c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "font_name = \"Times New Roman\"  # Change to any other installed serif font if needed\n",
    "\n",
    "# Set font properties using the font name\n",
    "font_properties = font_manager.FontProperties(family=font_name, size=18)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e746ddaf7390816f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from helper_functions.AD_funcs import Create_Transition_Mat, Create_Asym_Tran_Kernel\n",
    "def compute_kernels(s1_full, s1_ref, s2_full, s2_ref, s3_full, s4_full):\n",
    "    A1, _, _ = Create_Asym_Tran_Kernel(s1_full, s1_ref, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    A2, _, _ = Create_Asym_Tran_Kernel(s2_full, s2_ref, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    K1, _ = Create_Transition_Mat(s1_full, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    K2, _ = Create_Transition_Mat(s2_full, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    K1_ref, _ = Create_Transition_Mat(s1_ref, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    K2_ref, _ = Create_Transition_Mat(s2_ref, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    if sim_params['views'] == 'multi_frame':\n",
    "        K3, _ = Create_Transition_Mat(s3_full, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "        K4, _ = Create_Transition_Mat(s4_full, scale=sim_params['scale'], mode=sim_params['sigma_mode'])\n",
    "    else:\n",
    "        K3 = None\n",
    "        K4 = None\n",
    "    \n",
    "    return A1, A2, K1, K2, K1_ref, K2_ref, K3, K4\n",
    "\n",
    "# kernels_dict = dict()\n",
    "# kernels_dict['K1'] = K1\n",
    "# kernels_dict['K2'] = K2\n",
    "# kernels_dict['K1_ref'] = K1_ref\n",
    "# kernels_dict['K2_ref'] = K2_ref\n",
    "# kernels_dict['A1'] = A1\n",
    "# kernels_dict['A2'] = A2\n",
    "\n",
    "\n",
    "# with open(f\"{figures_path}/kernels_dict.pkl\", 'wb') as fp:\n",
    "#     pickle.dump(kernels_dict, fp)\n",
    "#     print('dictionary saved successfully to file')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c16261aa84ed06bd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from helper_functions.bickley_funcs import method_analysis, evaluate_metrics\n",
    "results = []\n",
    "for rep in tqdm(range(sim_params['reps'])):\n",
    "    embed_dict = dict()\n",
    "    # create data for rep\n",
    "    dataset, c = create_dataset(sim_params, figures_path)\n",
    "    # create views\n",
    "    s1_full, s2_full, s3_full, s4_full = create_views(dataset, sim_params)\n",
    "    s1_ref = s1_full[:Nr, :]\n",
    "    s2_ref = s2_full[:Nr, :]\n",
    "    # rep figures path \n",
    "    rep_path = f'{figures_path}/rep_{rep}'\n",
    "    os.makedirs(rep_path, exist_ok=True)\n",
    "    c_align = None\n",
    "    A1, A2, K1, K2, K1_ref, K2_ref, K3, K4 = compute_kernels(s1_full, s1_ref, s2_full, s2_ref, s3_full, s4_full)\n",
    "    for i, method in enumerate(sim_params['ad_methods']):\n",
    "        print(f'now processing method {method}, number {i+1} out of {len(sim_params['ad_methods'])}')\n",
    "        if method in {\"forward_only\", \"forward_only_slow\", \"alternating_roseland\", \"ffbb\", \"fbfb\", \"ncca\", \"kcca\", \"nystrom\", \"adm_plus\", 'backward_only'}:\n",
    "            embed, c = method_analysis(s1_ref, s1_full, s2_ref, s2_full, method=method,\n",
    "                                       sim_params=sim_params, figures_path=rep_path, K1=A1, K2=K2_ref, dataset=dataset, \n",
    "                                       font_properties=font_properties, c_align=c_align)\n",
    "        elif method in {\"kcca_impute\"}:\n",
    "            embed, c = method_analysis(s1_ref, s1_full, s2_ref, s2_full, method=method,\n",
    "                                       sim_params=sim_params, figures_path=rep_path, K1=K1, K2=K2_ref, dataset=dataset, \n",
    "                                       font_properties=font_properties, c_align=c_align)\n",
    "        elif method in {\"ad\", 'dm', 'ad_svd'}:\n",
    "            embed, c = method_analysis(s1_ref, s1_full, s2_ref, s2_full, method=method,\n",
    "                                       sim_params=sim_params, figures_path=rep_path, K1=K1, K2=K2, dataset=dataset, \n",
    "                                       font_properties=font_properties, c_align=c_align)\n",
    "        elif method == \"lead\":\n",
    "            embed, c = method_analysis(s1_ref, s1_full, s2_ref, s2_full, method=method,\n",
    "                                       sim_params=sim_params, figures_path=rep_path, K1=A1, K2=A2, dataset=dataset, \n",
    "                                       font_properties=font_properties, c_align=c_align)\n",
    "        else:\n",
    "            raise ValueError(f\"invalid method: {method}\")\n",
    "        if i == 0:\n",
    "            c_align = c\n",
    "        # save clustering and embedding to dictionary\n",
    "        embed_dict[method] = {'embed': embed, 'clustering': c, 's1': s1_full, 's2': s2_full}\n",
    "        # evaluate metrics\n",
    "        new_line = evaluate_metrics(s1_full, s2_full, c, embed, sim_params, K1, K2, K3, K4, method, rep)\n",
    "        results.append(new_line)\n",
    "    # save rep dictionary\n",
    "    with open(f\"{rep_path}/embedding_dictionary.pkl\", 'wb') as fp:\n",
    "        pickle.dump(embed_dict, fp)\n",
    "        print('dictionary saved successfully to file')\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['generalization_gap'] = results_df['dynamic_graph_isoperim_score_4'] - results_df['dynamic_graph_isoperim_score']\n",
    "results_df.to_csv(f'{figures_path}/results.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c678335e4ddc4c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "avg_results_df = results_df.groupby('method').mean()\n",
    "avg_results_df.to_csv(f'{figures_path}/average_results.csv')\n",
    "stats_columns = ['silhouette_score_embed', 'dynamic_graph_isoperim_score', 'dynamic_graph_isoperim_score_4', 'generalization_gap']\n",
    "stats_df = results_df.groupby('method')[stats_columns].agg(\n",
    "        ['mean', 'std']\n",
    "    ).reset_index()\n",
    "stats_df.to_csv(f'{figures_path}/stats_results.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ada137aeaed12d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Post Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c453a3c4073f94"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# compute confusion matrices for each method's clustering compared to clustering achieved by ADM\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from helper_functions.clustering_funcs import align_clusters_different_rep\n",
    "from helper_functions.bickley_funcs import plot_hit_or_miss, plot_wrapper\n",
    "methods_to_plot = ['ad', 'ncca', 'kcca_impute', 'adm_plus', 'nystrom', 'forward_only']\n",
    "reference_method = 'ad'\n",
    "annotate = False\n",
    "\n",
    "cm_path = f'{figures_path}/confusion_matrices'\n",
    "os.makedirs(cm_path, exist_ok=True)\n",
    "cm_dict = dict()\n",
    "for rep in tqdm(range(sim_params['reps'])):\n",
    "    rep_path = f'{figures_path}/rep_{rep}'\n",
    "    summary_path = f'{rep_path}/summary'\n",
    "    os.makedirs(summary_path, exist_ok=True)\n",
    "    with open(f\"{rep_path}/embedding_dictionary.pkl\", 'rb') as fp:\n",
    "        embed_dict = pickle.load(fp)\n",
    "    print('Dictionary Loaded Successfully')\n",
    "    c_ad = embed_dict[reference_method]['clustering']\n",
    "    # save first rep clustering to align the rest to it\n",
    "    if rep == 0:\n",
    "        c_align = c_ad\n",
    "        s1_align = embed_dict[reference_method]['s1']\n",
    "        s2_align = embed_dict[reference_method]['s2']\n",
    "    else:\n",
    "        c_ad = align_clusters_different_rep(s1=s1_align, label1=c_align, s2=embed_dict[reference_method]['s1'], label2=c_ad, metric='kde_correlation')\n",
    "    for i, method in enumerate(sim_params['ad_methods']):\n",
    "        # load clustering\n",
    "        c_curr = embed_dict[method]['clustering']\n",
    "        c_curr = align_clusters(c_ad, c_curr)\n",
    "        # initialize list of confusion matrices for each method\n",
    "        if method not in cm_dict.keys():\n",
    "            cm_dict[method] = []\n",
    "        # compute confusion matrix\n",
    "        cm = confusion_matrix(y_true=c_ad, y_pred=c_curr, normalize='true')\n",
    "        cm_dict[method].append(cm)\n",
    "\n",
    "        # plot hit or miss plot\n",
    "        if method in methods_to_plot:\n",
    "            plot_wrapper(data=embed_dict[method]['s2'], c=c_curr, c_ref=c_ad, figures_path=summary_path, method=method,\n",
    "                             font_properties=font_properties, sim_params=sim_params, cmap='custom', plot_type='hit-or-miss')\n",
    "            plot_wrapper(data=embed_dict[method]['s2'], c=c_curr, c_ref=c_ad, figures_path=summary_path, method=method,\n",
    "                             font_properties=font_properties, sim_params=sim_params, cmap='custom', plot_type='scatter')\n",
    "\n",
    "# plot mean and std confusion matrix\n",
    "for method in sim_params['ad_methods']:\n",
    "    # calcualte mean and std confusion matrix\n",
    "    cm_array = np.array(cm_dict[method])\n",
    "    mean_cm = np.mean(cm_array, axis=0)\n",
    "    std_cm = np.std(cm_array, axis=0)\n",
    "\n",
    "    # plot\n",
    "    class_names = np.arange(sim_params['clusters'])\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    fmt = \".2f\"\n",
    "    # Create annotation text with mean ± std\n",
    "    if annotate:\n",
    "        annotations = np.array([[f\"{mean:.2f}\\n±{std:.2f}\" for mean, std in zip(row_mean, row_std)]\n",
    "                                for row_mean, row_std in zip(mean_cm, std_cm)])\n",
    "    \n",
    "        sns.heatmap(mean_cm, annot=annotations, fmt=\"\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, vmin=0, vmax=1)\n",
    "    else:\n",
    "        sns.heatmap(mean_cm, fmt=\"\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, vmin=0, vmax=1)\n",
    "    \n",
    "    plt.xlabel(f'Predicted Sets', fontsize=26)\n",
    "    plt.ylabel(\"ADM Sets\", fontsize=26)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    cax = ax.figure.axes[-1]\n",
    "    cax.tick_params(labelsize=20)\n",
    "\n",
    "    plt.savefig(f'{cm_path}/confusion_matrix_{method}.pdf', dpi=500, format='pdf', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8da05c4d178a6c26",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embed_dict.keys()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ea7c29f8ed12c9b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deeptime Experiment code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6245ecd040b1040d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from deeptime.kernels import GaussianKernel\n",
    "# from deeptime.decomposition import KernelCCA\n",
    "# from deeptime.clustering import KMeans\n",
    "#\n",
    "# method = 'deeptime_kcca'\n",
    "#\n",
    "# # create kernel\n",
    "# sigma = sim_params['scale']\n",
    "# kernel = GaussianKernel(sigma)\n",
    "#\n",
    "# kcca_estimator = KernelCCA(kernel, n_eigs=9, epsilon=1e-3)\n",
    "# kcca_model = kcca_estimator.fit((s1_full, s2_full)).fetch_model()\n",
    "# embed = np.real(kcca_model.eigenvectors)\n",
    "# # perform kmeans\n",
    "# kmeans = KMeans(n_clusters=sim_params['clusters'], n_jobs=8).fit(embed).fetch_model()\n",
    "# c = kmeans.transform(embed)\n",
    "# c = align_clusters(c_align, c)\n",
    "# if sim_params['animate']:\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "#     ani = dataset.make_animation(c=c/sim_params['clusters'], agg_backend=False, interval=75, fig=fig, ax=ax, s=50)\n",
    "#     ani.save(f'{figures_path}/{method}_clustering_animation.mp4', writer='ffmpeg', fps=30, dpi=300)\n",
    "# plot_clustering(dataset, c, figures_path, method, cmap=sim_params['cmap'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7049e467661fdad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# grid1, grid2, score, _, _ = dynamic_isoperimetric_score(s1_full, s2_full, c, grid_size_x=50, grid_size_y=15, bounds=(0, -3, 20, 3))\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# # grid1 = create_grid(s2_full, c, grid_size_x=50, grid_size_y=15, bounds=(0, -3, 20, 3))\n",
    "# plt.imshow(grid2.T, origin='lower', cmap='Dark2')\n",
    "# plt.colorbar(label='Cluster Label')\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.show()\n",
    "# print(f'isoperimetric score {score}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "370884a9d93ce6a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# grid = np.meshgrid(np.linspace(0, 20, 150), np.linspace(-3, 3, 50))\n",
    "# xy = np.dstack(grid).reshape(-1, 2)\n",
    "# z = kcca_model.transform(xy).real\n",
    "# \n",
    "# fig = plt.figure(figsize=(12, 10))\n",
    "# gs = fig.add_gridspec(ncols=2, nrows=3)\n",
    "# \n",
    "# for row in range(3):\n",
    "#     for col in range(2):\n",
    "#         ix = col + 2*row\n",
    "#         ax = fig.add_subplot(gs[row, col])\n",
    "#         ax.contourf(grid[0], grid[1], z[:, ix].reshape(grid[0].shape), levels=15)\n",
    "#         ax.set_title(f\"Eigenfunction {ix+1}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75fb33c24aabc77c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
